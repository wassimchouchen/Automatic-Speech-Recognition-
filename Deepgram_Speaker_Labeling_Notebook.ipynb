{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wassimchouchen/Automatic-Speech-Recognition-/blob/main/Deepgram_Speaker_Labeling_Notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Transcribe any audio file with Deepgram!\n",
        "\n",
        "**Make a copy of this notebook into your own drive, and follow the instructions below!** ü•≥ü•≥ü•≥\n",
        "\n",
        "\n",
        "----------------------------\n",
        "\n",
        "# Get started:\n",
        "\n",
        "1) Copy this notebook (`File > Save a copy in Drive`) or download the .ipynb (`File > Download > Download as .ipynb`).\n",
        "\n",
        "2) Follow the instructions below!\n",
        "\n",
        "----------------------------\n",
        "#Instructions:\n",
        "\n",
        "Running the following three cells will allow you to transcribe and diarize any audio you wish. That is, your output should contain labeled speakers. The comments in the code below point out the variables you can manipulate to modify your output as you desire.\n",
        "\n",
        "Before running this notebook, you'll need to have a couple audio files on-hand\n",
        "that you wish to transcribe. Once you have those files in a folder, you should be able to transcribe as you please. Just specify the filepaths as outlined below!\n",
        "\n",
        "And by the way, if you haven't yet signed up for Deepgram, check out this link here: https://dpgr.am/7407694"
      ],
      "metadata": {
        "id": "VN53w-RMPxVK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 1: Dependencies\n",
        "\n",
        "Run this cell to download all necessary dependencies.\n",
        "\n",
        "Note: You can run a cell by clicking the play button on the left or by clicking on the cell and pressing `shift`+`ENTER` at the same time. (Or `shift` + `return` on Mac)."
      ],
      "metadata": {
        "id": "ytg278L-QhAr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install requests ffmpeg-python\n",
        "! pip install deepgram-sdk --upgrade"
      ],
      "metadata": {
        "id": "tDNAqesZNFB4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "afca7883-53f6-4bd7-c779-4fcf73c46de0"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.27.1)\n",
            "Collecting ffmpeg-python\n",
            "  Downloading ffmpeg_python-0.2.0-py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.4)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from ffmpeg-python) (0.18.3)\n",
            "Installing collected packages: ffmpeg-python\n",
            "Successfully installed ffmpeg-python-0.2.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting deepgram-sdk\n",
            "  Downloading deepgram_sdk-2.5.0-py3-none-any.whl (17 kB)\n",
            "Collecting aiohttp (from deepgram-sdk)\n",
            "  Downloading aiohttp-3.8.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting websockets (from deepgram-sdk)\n",
            "  Downloading websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->deepgram-sdk) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->deepgram-sdk) (2.0.12)\n",
            "Collecting multidict<7.0,>=4.5 (from aiohttp->deepgram-sdk)\n",
            "  Downloading multidict-6.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3 (from aiohttp->deepgram-sdk)\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting yarl<2.0,>=1.0 (from aiohttp->deepgram-sdk)\n",
            "  Downloading yarl-1.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m26.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting frozenlist>=1.1.1 (from aiohttp->deepgram-sdk)\n",
            "  Downloading frozenlist-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (149 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiosignal>=1.1.2 (from aiohttp->deepgram-sdk)\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.0->aiohttp->deepgram-sdk) (3.4)\n",
            "Installing collected packages: websockets, multidict, frozenlist, async-timeout, yarl, aiosignal, aiohttp, deepgram-sdk\n",
            "Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 deepgram-sdk-2.5.0 frozenlist-1.3.3 multidict-6.0.4 websockets-11.0.3 yarl-1.9.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 2: Upload audio files to this Colab!\n",
        "\n",
        "On the left, you'll see a side-bar with a folder icon. Click that icon, and you'll see a series of folders. This is where you'll upload your audios.\n",
        "\n",
        "You can upload your files directly into this directory by clicking the upload icon in the top left. The icon looks like a sheet of paper with an upwards-pointing arrow on it.\n",
        "\n",
        "Click the upload icon and select the audio file you wish to transcribe. It will take a few moments for the audio to appear, but once it does, move onto Step 3."
      ],
      "metadata": {
        "id": "Hazx372AOB0v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Have you completed Step 2 above? üëÄ\n",
        "# Do you see all your desired audio file(s) in the folder on the left? üìÇ"
      ],
      "metadata": {
        "id": "MiX4C4vyPKJG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 3: Transcription\n",
        "\n",
        "Fill in the following variables:\n",
        "\n",
        "\n",
        "* `dg_key` = Your personal Deepgram API key\n",
        "* `MIMETYPE` = the type of audio file you're working with (mp3, mp4, m4a, etc.)\n",
        "* `DIRECTORY` = The name of the folder that contains the audio(s) you wish to transcribe. Note, unless you created a new folder for your audios, the default `'.'` value should be fine. (Or, if you placed your audio file in the default `sample_data` folder, set the value of `DIRECTORY` to `sample_data`.)\n",
        "\n",
        "\n",
        "Now run the cell! (`Shift` + `Enter`)\n",
        "\n",
        "-----------\n",
        "\n",
        "\n",
        "\n",
        "And by the way, if you're already a Deepgram user, and you're getting an error in this cell the most common fixes are:\n",
        "\n",
        "1. You may need to update your installation of the deepgram-sdk.\n",
        "2. You may need to check how many credits you have left in your Deepgram account."
      ],
      "metadata": {
        "id": "jql62j9YQrai"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from deepgram import Deepgram\n",
        "import asyncio, json, os\n",
        "\n",
        "'''\n",
        " Sign up at https://dpgr.am/7407694\n",
        " to get an API key and 45,000 minutes\n",
        " for free!\n",
        "'''\n",
        "dg_key = '932ffbfc9daaba5b03b12415537979aa72731b1e'\n",
        "dg = Deepgram(dg_key)\n",
        "\n",
        "'''\n",
        "The most common audio formats and encodings we support\n",
        "include mp3, mp4, mp2, aac, wav, flac, pcm, m4a, ogg, opus, and webm,\n",
        "So feel free to adjust the `MIMETYPE` variable as needed\n",
        "'''\n",
        "MIMETYPE = 'wav'\n",
        "\n",
        "#Note: You can use '.' if your audio is in the root\n",
        "DIRECTORY = '.'\n",
        "\n",
        "\n",
        "# Feel free to modify your model's parameters as you wish!\n",
        "options = {\n",
        "    \"punctuate\": True,\n",
        "    \"diarize\": True,\n",
        "    \"model\": 'general',\n",
        "    \"tier\": 'nova'\n",
        "}\n",
        "\n",
        "#This function is what calls on the model to transcribe\n",
        "def main():\n",
        "    audio_folder = os.listdir(DIRECTORY)\n",
        "    for audio_file in audio_folder:\n",
        "        if audio_file.endswith(MIMETYPE):\n",
        "          with open(f\"{DIRECTORY}/{audio_file}\", \"rb\") as f:\n",
        "              source = {\"buffer\": f, \"mimetype\":'audio/'+MIMETYPE}\n",
        "              res = dg.transcription.sync_prerecorded(source, options)\n",
        "              with open(f\"./{audio_file[:-4]}.json\", \"w\") as transcript:\n",
        "                  json.dump(res, transcript, indent=4)\n",
        "    return\n",
        "\n",
        "main()"
      ],
      "metadata": {
        "id": "mlQVesiDOeAf"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "If the cell above succeeds, you should see JSON output file(s) as siblings\n",
        "next to your audio files.\n",
        "\n",
        "Note: There may be a small delay between when the cell finishes running\n",
        "and when the JSON appears. This is normal. Just wait a few moments for\n",
        "the JSON(s) to appear. It should take less than a minute, depending on\n",
        "the size of your file(s).\n",
        "'''"
      ],
      "metadata": {
        "id": "ecHKxy0q6_fu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 4: Check out your transcription!\n",
        "\n",
        "The function below parses the output JSON and prints out the pure transcription of one of the files you just transcribed! (Make sure\n",
        "the file you're trying to examine is indeed already loaded into the\n",
        "folder on the left!)\n",
        "\n",
        "Then run this cell (`Shift`+`Enter`) to see a speaker-labeled transcription of your audio!\n",
        "\n",
        "\n",
        "----\n",
        "\n",
        "Note: Due to Colab's underlying functionality, there will be a slight delay\n",
        "between the moment this cell finishes running and the moment that the output\n",
        ".txt file appears in the folder on the left-hand side of your screen.\n",
        "\n",
        "This delay should take less than a minute, depending on how large the file is. Nevertheless, just wait a moment, and your transcript will appear! **bold text**"
      ],
      "metadata": {
        "id": "dAVvWh7yRAnx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "The JSON is loaded with information, but if you just want to read the\n",
        "transcript, run the code below!\n",
        "\n",
        "One .txt file will be generated per JSON; this .txt file will contain\n",
        "the diarized, human-readable transcript.\n",
        "'''\n",
        "\n",
        "TAG = 'SPEAKER '\n",
        "\n",
        "def create_transcript(output_json, output_transcript):\n",
        "  lines = []\n",
        "  with open(output_json, \"r\") as file:\n",
        "    words = json.load(file)[\"results\"][\"channels\"][0][\"alternatives\"][0][\"words\"]\n",
        "    curr_speaker = 0\n",
        "    curr_line = ''\n",
        "    for word_struct in words:\n",
        "      word_speaker = word_struct[\"speaker\"]\n",
        "      word = word_struct[\"punctuated_word\"]\n",
        "      if word_speaker == curr_speaker:\n",
        "        curr_line += ' ' + word\n",
        "      else:\n",
        "        tag = TAG + str(curr_speaker) + ':'\n",
        "        full_line = tag + curr_line + '\\n'\n",
        "        curr_speaker = word_speaker\n",
        "        lines.append(full_line)\n",
        "        curr_line = ' ' + word\n",
        "    lines.append(TAG + str(curr_speaker) + ':' + curr_line)\n",
        "    with open(output_transcript, 'w') as f:\n",
        "      for line in lines:\n",
        "        f.write(line)\n",
        "        f.write('\\n')\n",
        "  return\n",
        "\n",
        "def print_transcript():\n",
        "  for filename in os.listdir(DIRECTORY):\n",
        "    if filename.endswith('.json'):\n",
        "      output_transcript = os.path.splitext(filename)[0] + '.txt'\n",
        "      create_transcript(filename, output_transcript)\n",
        "\n",
        "print_transcript()"
      ],
      "metadata": {
        "id": "e7CgWdImOs-E"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "If you see a .txt file appear in the folder on the left-hand\n",
        "side of the screen, that means your speaker-labeled (read: diarized)\n",
        "transcript has been generated!\n",
        "\n",
        "Click into that file to read it. Or, if you wish to print the\n",
        "transcript down below, run this cell!\n",
        "'''\n",
        "\n",
        "SEPARATOR = '--------------------------'\n",
        "\n",
        "def print_lines(filename):\n",
        "  with open(filename, 'r') as f:\n",
        "    for line in f:\n",
        "      print(line)\n",
        "\n",
        "def print_transcript():\n",
        "  for filename in os.listdir(DIRECTORY):\n",
        "    if filename.endswith('.txt'):\n",
        "      print_lines(filename)\n",
        "      print(SEPARATOR)\n",
        "\n",
        "print_transcript()"
      ],
      "metadata": {
        "id": "A7vZ9iVGDVXo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "270c996e-c754-47a7-9932-984cd1164028"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SPEAKER 0: Contest k t n rendez vous. Deux, Esque de voir, doctor. Catra. The contest is going to be proposed the veneer, sank,\n",
            "\n",
            "--------------------------\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.10.1 ('dg_plus_yt': venv)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.1"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "9ccb4f31e81b19d196bbac066caca5d222f2bb20938f55af05f3ca51e34eca69"
      }
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}